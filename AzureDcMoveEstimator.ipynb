{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pricing json files for VM and disks can be downloaded fron the following links.\n",
    "\n",
    "VM link:\n",
    "https://azure.microsoft.com/api/v3/pricing/virtual-machines/calculator/?discount=mosp&showSkus=true&showGuids=true&currency=eur\n",
    "\n",
    "Disks link:\n",
    "https://azure.microsoft.com/api/v2/pricing/managed-disks/calculator/?culture=en-us&discount=mosp&showSkus=true&showGuids=true&currency=eur\n",
    "\n",
    "Site Recovery link:\n",
    "https://azure.microsoft.com/api/v2/pricing/site-recovery/calculator/?culture=en-us&discount=mosp&showSkus=true&showGuids=true&currency=eur\n",
    "\n",
    "If, before downloading the files, you open the azure calculator at https://azure.microsoft.com/en-us/pricing/calculator/ and login to the platform, the json will also include a column reporting the sku number (if you don't login, the column with sku will not be included in the json). \n",
    "\n",
    "To download the files, open the above link and save the resulting json in the \"data\" folder with names \"vm_pricing_table.json\", \"disk_pricing_table.json\", and \"site_recovery_pricing_table.json\"\n",
    "\n",
    "You will find a version of the json files already in the \"data\" folder and you may update them with a more recent version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are to open and prepare the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join('.','data', 'vm_pricing_table.json')) as f:\n",
    "    vm_pricing_table = json.load(f)\n",
    "    \n",
    "vm_pricing_table_offers = vm_pricing_table['offers']\n",
    "vm_pricing_table_offers = pd.DataFrame(vm_pricing_table_offers).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.','data','disk_pricing_table.json')) as f:\n",
    "    disk_pricing_table = json.load(f)\n",
    "\n",
    "disk_pricing_table_offers = disk_pricing_table['offers']\n",
    "disk_pricing_table_offers = pd.DataFrame(disk_pricing_table_offers).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.','data','site_recovery_pricing_table.json')) as f:\n",
    "    site_recovery_pricing_table = json.load(f)\n",
    "\n",
    "site_recovery_pricing_offers = site_recovery_pricing_table['offers']['recover-to-azure']\n",
    "site_recovery_pricing_offers = pd.DataFrame(site_recovery_pricing_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the imported json files from data that are not needed and which would create issues\n",
    "disk_pricing_table_offers.reset_index(inplace=True)\n",
    "disk_pricing_table_offers.rename(columns = {'index':'diskName'}, inplace = True)\n",
    "disk_pricing_table_offers = disk_pricing_table_offers[~disk_pricing_table_offers['diskName'].str.match('.*mount.*')]\n",
    "\n",
    "vm_pricing_table_offers.reset_index(inplace=True)\n",
    "vm_pricing_table_offers.rename(columns = {'index':'vmName'}, inplace = True)\n",
    "vm_pricing_table_offers = vm_pricing_table_offers[~vm_pricing_table_offers['vmName'].str.match('.*lowpriority.*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the input BOM file\n",
    "input_bom = pd.read_excel(os.path.join('.','inputs','input_bom.xlsm'))\n",
    "# input_bom = input_bom[pd.to_numeric(input_bom['coresReq'], errors='coerce')>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the discount file (this file includes sku codes and associated discounts)\n",
    "input_sku_discount = pd.read_excel(os.path.join('.','inputs','input_sku_discounts.xlsx'))\n",
    "input_sku_discount.set_index('sku', inplace=True)\n",
    "discount_default_payg = input_sku_discount.loc['default_payg']['discount']\n",
    "discount_default_reserved = input_sku_discount.loc['default_reserved']['discount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are needed to extract key values from the json file. These functions will be used in Pandas dataframe apply statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing fuctions to extract values row by row from the json files.\n",
    "def discount(sku_string: str):\n",
    "    try:\n",
    "        return input_sku_discount.loc[sku_string]['discount']\n",
    "    except:\n",
    "        return discount_default_payg\n",
    "\n",
    "def extract_price_disk(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices'][region]['value']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_price_payg(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices']['perhour'][region]['value']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_price_3yr(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices']['perhourthreeyearreserved'][region]['value']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_price_1yr(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices']['perhouroneyearreserved'][region]['value']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_sku(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['partNumbers'][region]['sku']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_redhat_sku_payg(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['partNumbers']['global']['sku']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_redhat_price_payg(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices']['perhour']['global']['value']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_redhat_price_res1y(row: pd.Series, region: str):\n",
    "    try:\n",
    "        return row['prices']['perhouroneyearreserved']['global']['value']\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop is reading line by line the BOM and, for each row, is finding the machine and disk that satisfy the input conditions (requested vcpu, ram, ...) and cost less. The algorithm is simply taking the price list sorted by price, filtering it by the input conditions, and taking the first entry, which has the lowest price.\n",
    "For disks, a slightly moore complex logic in implemented because multiple disk can be used in striping. A striping of multiple disks may better fit the requirements (e.g. if requirement is for 90 GB, then three 32 GB disks in striping will cost less than one 128 GB disk). A table of available disk size and striping combination is created. This table depend on the max number of disks that are allowed in striping, which is an input, and is constructed by combining the base sizes (4, 8, 16, 32, ...) multiplied by the possible number of disks (1, 2, 3, ..., max) up to the maximum defined. After this table is created, it is sorted, and the smallest combination that satisfies the customer need is identified. This combination is then quoted searching on the price list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparign a table of possible disk sizes which is used in the loop below to select the best combination of disks\n",
    "disk_sizes = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32767]\n",
    "disk_sizes = pd.DataFrame(disk_sizes, columns=[\"size\"])\n",
    "disk_sizes['units'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using region: switzerland-north\n",
      "using disk max num: 1\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "region = ''\n",
    "disk_max_num = 0\n",
    "# set the following to True if the json pricing files include part numbers\n",
    "# the part numbers are included only if you logged in to the Azure Pricing Calculator before downloading the json files\n",
    "json_pricing_files_include_part_numbers = True\n",
    "error_message_stage = \"stage: 0\"\n",
    "for row in input_bom.itertuples():\n",
    "    row_dict = row._asdict()\n",
    "\n",
    "    if row.do_compute == \"yes\":\n",
    "        if region != row.region:\n",
    "            region = row.region\n",
    "            print(f'using region: {region}')\n",
    "\n",
    "            vm_pricing_table_offers_payg = vm_pricing_table_offers.copy()\n",
    "            vm_pricing_table_offers_payg['priceVM'] = vm_pricing_table_offers_payg.apply(lambda row: extract_price_payg(row, region), axis=1)\n",
    "            vm_pricing_table_offers_payg['skuVM'] = vm_pricing_table_offers_payg.apply(lambda row: extract_sku(row, region), axis=1)\n",
    "            vm_pricing_table_offers_payg.drop(['prices'], axis=1, inplace=True)\n",
    "            if json_pricing_files_include_part_numbers:\n",
    "                vm_pricing_table_offers_payg.drop(['partNumbers'], axis=1, inplace=True)\n",
    "            vm_pricing_table_offers_payg = vm_pricing_table_offers_payg.join(input_sku_discount,on='skuVM')\n",
    "            vm_pricing_table_offers_payg['discount'] = vm_pricing_table_offers_payg['discount'].fillna(discount_default_payg)\n",
    "            vm_pricing_table_offers_payg.rename(columns = {'discount':'discountVm'}, inplace = True)\n",
    "            vm_pricing_table_offers_payg['priceVmDiscounted'] = vm_pricing_table_offers_payg['priceVM'] * (1-vm_pricing_table_offers_payg['discountVm'])\n",
    "            vm_pricing_table_offers_payg['sortMetric_pricePlusHiddenLicense'] = vm_pricing_table_offers_payg['priceVmDiscounted'] + vm_pricing_table_offers_payg['cores'] * row.hiddenLicenseCost\n",
    "            vm_pricing_table_offers_payg.sort_values('sortMetric_pricePlusHiddenLicense', inplace=True)\n",
    "\n",
    "            vm_pricing_table_offers_3y = vm_pricing_table_offers.copy()\n",
    "            vm_pricing_table_offers_3y['priceVM'] = vm_pricing_table_offers_3y.apply(lambda row: extract_price_3yr(row, region), axis=1)\n",
    "            vm_pricing_table_offers_3y['skuVM'] = vm_pricing_table_offers_3y.apply(lambda row: extract_sku(row, region), axis=1)\n",
    "            vm_pricing_table_offers_3y.drop(['prices'], axis=1, inplace=True)\n",
    "            if json_pricing_files_include_part_numbers:\n",
    "                vm_pricing_table_offers_3y.drop(['partNumbers'], axis=1, inplace=True)\n",
    "            vm_pricing_table_offers_3y['discount'] = discount_default_reserved\n",
    "            vm_pricing_table_offers_3y.rename(columns = {'discount':'discountVm'}, inplace = True)\n",
    "            vm_pricing_table_offers_3y['priceVmDiscounted'] = vm_pricing_table_offers_3y['priceVM'] * (1-vm_pricing_table_offers_3y['discountVm'])\n",
    "            vm_pricing_table_offers_3y['sortMetric_pricePlusHiddenLicense'] = vm_pricing_table_offers_3y['priceVmDiscounted'] + vm_pricing_table_offers_3y['cores'] * row.hiddenLicenseCost\n",
    "            vm_pricing_table_offers_3y.sort_values('sortMetric_pricePlusHiddenLicense', inplace=True)\n",
    "\n",
    "            disk_pricing_table_offers_w = disk_pricing_table_offers.copy()\n",
    "            disk_pricing_table_offers_w['priceDisk'] = disk_pricing_table_offers_w.apply(lambda row: extract_price_disk(row, region), axis=1)\n",
    "            disk_pricing_table_offers_w['skuDisk'] = disk_pricing_table_offers_w.apply(lambda row: extract_sku(row, region), axis=1)\n",
    "            disk_pricing_table_offers_w.drop(['prices'], axis=1, inplace=True)\n",
    "            if json_pricing_files_include_part_numbers:\n",
    "                disk_pricing_table_offers_w.drop(['partNumbers'], axis=1, inplace=True)\n",
    "            disk_pricing_table_offers_w = disk_pricing_table_offers_w.join(input_sku_discount,on='skuDisk')\n",
    "            disk_pricing_table_offers_w['discount'] = disk_pricing_table_offers_w['discount'].fillna(discount_default_payg)\n",
    "            disk_pricing_table_offers_w.rename(columns = {'discount':'discountDisk'}, inplace = True)\n",
    "            disk_pricing_table_offers_w['priceDiskDiscounted'] = disk_pricing_table_offers_w['priceDisk'] * (1-disk_pricing_table_offers_w['discountDisk'])\n",
    "            disk_pricing_table_offers_w.sort_values('priceDiskDiscounted', inplace=True)\n",
    "\n",
    "            vm_pricing_table_offers_redhat = vm_pricing_table_offers.copy()\n",
    "            vm_pricing_table_offers_redhat = vm_pricing_table_offers_redhat[vm_pricing_table_offers_redhat['vmName'].str.match(r'redhat-[0-9]+.*core')]\n",
    "            vm_pricing_table_offers_redhat['priceRedHatPayg'] = vm_pricing_table_offers_redhat.apply(lambda row: extract_redhat_price_payg(row, region), axis=1)\n",
    "            vm_pricing_table_offers_redhat['priceRedHatRes1y'] = vm_pricing_table_offers_redhat.apply(lambda row: extract_redhat_price_res1y(row, region), axis=1)\n",
    "            vm_pricing_table_offers_redhat['skuRedHat'] = vm_pricing_table_offers_redhat.apply(lambda row: extract_redhat_sku_payg(row, region), axis=1)\n",
    "            vm_pricing_table_offers_redhat = vm_pricing_table_offers_redhat[['vmName', 'cores', 'priceRedHatPayg', 'priceRedHatRes1y', 'skuRedHat']]\n",
    "            vm_pricing_table_offers_redhat.sort_values('cores', inplace=True)\n",
    "        \n",
    "        # select best vm reserved 3y\n",
    "        try:\n",
    "            if not (row.coresReq > 0 and row.ramReq > 0):\n",
    "                raise Exception('VM data is missing')\n",
    "\n",
    "            error_message_stage = \"stage: 1\"\n",
    "            ptable = vm_pricing_table_offers_3y.copy()\n",
    "            ptable = ptable[ptable['cores'] >= row.coresReq]\n",
    "            ptable = ptable[ptable['ram'] >= row.ramReq]\n",
    "            ptable = ptable[ptable['vmName'].str.match(row.regexVm)]\n",
    "            ptable = ptable[ptable['skuVM'].notnull()]\n",
    "            selected_vm = dict(ptable.iloc[0].add_suffix(\"_res3y\"))\n",
    "            row_dict.update(selected_vm)\n",
    "\n",
    "            error_message_stage = \"stage: 2\"\n",
    "            ptable = vm_pricing_table_offers_payg.copy()\n",
    "            ptable = ptable[ptable['cores'] >= row.coresReq]\n",
    "            ptable = ptable[ptable['ram'] >= row.ramReq]\n",
    "            ptable = ptable[ptable['vmName'].str.match(row.regexVm)]\n",
    "            ptable = ptable[ptable['skuVM'].notnull()]\n",
    "            selected_vm = dict(ptable.iloc[0].add_suffix(\"_payg\"))\n",
    "            row_dict.update(selected_vm)\n",
    "\n",
    "            error_message_stage = \"stage: 2 win\"\n",
    "            ptable = vm_pricing_table_offers_payg.copy()\n",
    "            ptable = ptable[ptable['cores'] >= row.coresReq]\n",
    "            ptable = ptable[ptable['ram'] >= row.ramReq]\n",
    "            ptable = ptable[ptable['vmName'].str.match('windows')]\n",
    "            ptable = ptable[ptable['vmName'].str.match(row.regexVm)]\n",
    "            ptable = ptable[ptable['skuVM'].notnull()]\n",
    "            #ptable = ptable[ptable['priceVM'].notnull()]\n",
    "            selected_vm = dict(ptable.iloc[0].add_suffix(\"_payg_Windows\"))\n",
    "            row_dict.update(selected_vm)\n",
    "\n",
    "            error_message_stage = \"stage: 2 redhat\"\n",
    "            ptable = vm_pricing_table_offers_redhat.copy()\n",
    "            ptable = ptable[ptable['cores'] >= row_dict['cores_payg']]\n",
    "            ptable = ptable[ptable['skuRedHat'].notnull()]\n",
    "            selected_vm = dict(ptable.iloc[0].add_suffix(\"_payg_RedHat\"))\n",
    "            row_dict.update(selected_vm)\n",
    "\n",
    "            row_dict['windowsLicenseCores'] = 8 if (row_dict['cores_payg'] <= 8) else math.ceil(row_dict['cores_payg']/16) * 16\n",
    "\n",
    "            error_message_stage = \"stage: 3\"\n",
    "            # select best pricing model (payg vs reserved), and compute price per month \n",
    "            vm_cost_per_month_res3y = row_dict['priceVM_res3y'] * 730\n",
    "            vm_cost_per_month_payg = row_dict['priceVM_payg'] * row.hoursPerMonth\n",
    "            vm_cost_per_month_discounted_res3y = row_dict['priceVmDiscounted_res3y'] * 730\n",
    "            vm_cost_per_month_discounted_payg = row_dict['priceVmDiscounted_payg'] * row.hoursPerMonth\n",
    "            if(vm_cost_per_month_discounted_res3y < vm_cost_per_month_discounted_payg):\n",
    "                row_dict['vmBestPricingModel'] = 'reserved3y'\n",
    "                row_dict['VMcostPerMonth'] = vm_cost_per_month_res3y\n",
    "                row_dict['VMcostPerMonthDiscounted'] = vm_cost_per_month_discounted_res3y\n",
    "                row_dict['vmSelected'] = row_dict['vmName_res3y']\n",
    "                row_dict['vmSkuSelected'] = row_dict['skuVM_res3y']\n",
    "                row_dict['discountVm'] = row_dict['discountVm_res3y']\n",
    "            else:\n",
    "                row_dict['vmBestPricingModel'] = 'payg'\n",
    "                row_dict['VMcostPerMonth'] = vm_cost_per_month_payg\n",
    "                row_dict['VMcostPerMonthDiscounted'] = vm_cost_per_month_discounted_payg\n",
    "                row_dict['vmSelected'] = row_dict['vmName_payg']\n",
    "                row_dict['vmSkuSelected'] = row_dict['skuVM_payg']\n",
    "                row_dict['discountVm'] = row_dict['discountVm_payg']\n",
    "\n",
    "            row_dict['VMcostPerMonthPayg'] = vm_cost_per_month_payg\n",
    "            row_dict['VMcostPerMonthPaygDiscounted'] = vm_cost_per_month_discounted_payg\n",
    "            row_dict['VMcostPerMonthPayg730h'] = row_dict['priceVM_payg'] * 730\n",
    "            row_dict['VMcostPerMonthPayg730hDiscounted'] = row_dict['priceVmDiscounted_payg'] * 730\n",
    "\n",
    "            if not (row.storageReq > 0):\n",
    "                raise Exception('Disk data is missing')\n",
    "\n",
    "            error_message_stage = \"stage: 4\"\n",
    "            if disk_max_num != row.disksMaxNum:\n",
    "                disk_max_num = row.disksMaxNum\n",
    "                disk_striped_table = disk_sizes.copy()\n",
    "                for i in range(disk_max_num-1):\n",
    "                    disk_striped_table = pd.concat([disk_striped_table, disk_sizes*(i+2)])\n",
    "                disk_striped_table.sort_values(['size', 'units'], inplace=True)\n",
    "                print(f'using disk max num: {disk_max_num}')\n",
    "            \n",
    "            disk_striped = disk_striped_table[disk_striped_table['size'] >= row.storageReq].iloc[0]\n",
    "\n",
    "            error_message_stage = \"stage: 5\"\n",
    "            # select best disk\n",
    "            ptable = disk_pricing_table_offers_w.copy()\n",
    "            ptable = ptable[ptable['size'] != 0]\n",
    "            ptable = ptable[ptable['size'] >= disk_striped['size']/disk_striped['units']]\n",
    "            ptable = ptable[ptable['diskName'].str.match(row.regexDisk)]\n",
    "            ptable = ptable[ptable['skuDisk'].notnull()]\n",
    "            selected_disk = dict(ptable.iloc[0].add_suffix('_data_disk'))\n",
    "            \n",
    "            selected_disk['dataDiskBestPricingModel'] = 'reserved3y' if ('year' in selected_disk['diskName_data_disk']) else 'payg'\n",
    "\n",
    "            selected_disk['numDisksUsed'] = math.ceil(row.storageReq / selected_disk['size_data_disk'])\n",
    "            selected_disk['disksCostPerMonth'] = selected_disk['numDisksUsed'] * selected_disk['priceDisk_data_disk']\n",
    "            selected_disk['disksCostPerMonthDiscounted'] = selected_disk['disksCostPerMonth'] * (1 - selected_disk['discountDisk_data_disk'])\n",
    "\n",
    "            if json_pricing_files_include_part_numbers:\n",
    "                selected_disk['drDiskSku'] = disk_pricing_table_offers.set_index('diskName').loc[selected_disk['diskName_data_disk']]['partNumbers'][row.drRegion]['sku']\n",
    "            selected_disk['drDiskPrice'] = disk_pricing_table_offers.set_index('diskName').loc[selected_disk['diskName_data_disk']]['prices'][row.drRegion]['value']\n",
    "            selected_disk['discountDiskDr'] = discount(selected_disk['drDiskSku'])\n",
    "            \n",
    "            row_dict.update(selected_disk)\n",
    "\n",
    "            row_dict['siteRecoveryPrice'] = site_recovery_pricing_offers.loc[region]['prices']['value']\n",
    "            if json_pricing_files_include_part_numbers:\n",
    "                row_dict['siteRecoverySku'] = site_recovery_pricing_offers.loc[region]['partNumbers']['sku']\n",
    "\n",
    "            disk_type = re.search('^[^-]*-', row_dict['diskName_data_disk']).group(0)\n",
    "            if disk_type == 'standardhdd-':\n",
    "                snapshot_type = f'standardhdd-snapshot-lrs'\n",
    "            else:\n",
    "                snapshot_type = f'{disk_type}snapshot'\n",
    "\n",
    "            row_dict['snapshotPrice'] = disk_pricing_table['offers'][snapshot_type]['prices'][region]['value']\n",
    "\n",
    "            #disk_pricing_table['offers'][row_dict['diskName']]['prices'][region]['value']\n",
    "\n",
    "            error_message_stage = \"stage: 6\"\n",
    "            ptable = disk_pricing_table_offers_w.copy()\n",
    "            ptable = ptable[ptable['size'] != 0]\n",
    "            ptable = ptable[ptable['size'] >= row.osDiskSize]\n",
    "            ptable = ptable[ptable['diskName'].str.match(row.osDiskRegex)]\n",
    "            ptable = ptable[ptable['skuDisk'].notnull()]\n",
    "            os_disk = dict(ptable.iloc[0].add_suffix('_OS_disk'))\n",
    "            os_disk['osDiskBestPricingModel'] = 'reserved3y' if ('year' in os_disk['diskName_OS_disk']) else 'payg'\n",
    "            os_disk['disksCostPerMonth_OS'] = os_disk['priceDisk_OS_disk']\n",
    "            os_disk['disksCostPerMonthDiscounted_OS'] = os_disk['disksCostPerMonth_OS'] * (1 - os_disk['discountDisk_OS_disk'])\n",
    "            row_dict.update(os_disk)\n",
    "\n",
    "        except BaseException as error:\n",
    "            print(f'error on: {row.id}, {error_message_stage}, message: \"{error}\"')\n",
    "            # traceback.print_last()\n",
    "\n",
    "    # add selected vm\n",
    "    output.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output list is converted to Pandas dataframe and exported in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'iaas_bom_quoted.xlsx'\n",
    "if os.path.isfile(os.path.join('.','outputs',output_file_name)):\n",
    "    os.remove(os.path.join('.','outputs',output_file_name))\n",
    "output.to_excel(os.path.join('.','outputs',output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKUs_VM_payg = output[(output['vmBestPricingModel']=='payg') & (output['Scope']=='In Scope')][['vmBestPricingModel', 'vmSelected', 'skuVM_payg', 'VMcostPerMonth']]\n",
    "SKUs_VM_payg.columns = ['pricingModel', 'name', 'SKU', 'CostPerMonth']\n",
    "SKUs_VM_res3y = output[(output['vmBestPricingModel']=='reserved3y') & (output['Scope']=='In Scope')][['vmBestPricingModel', 'vmSelected', 'skuVM_res3y', 'VMcostPerMonth']]\n",
    "SKUs_VM_res3y.columns = ['pricingModel', 'name', 'SKU', 'CostPerMonth']\n",
    "SKUs_data_disk = output[(output['Scope']=='In Scope')][['dataDiskBestPricingModel', 'diskName_data_disk', 'skuDisk_data_disk', 'disksCostPerMonth']]\n",
    "SKUs_data_disk.columns = ['pricingModel', 'name', 'SKU', 'CostPerMonth']\n",
    "SKUs_OS_disk = output[(output['Scope']=='In Scope')][['osDiskBestPricingModel', 'diskName_OS_disk', 'skuDisk_OS_disk', 'disksCostPerMonth_OS']]\n",
    "SKUs_OS_disk.columns = ['pricingModel', 'name', 'SKU', 'CostPerMonth']\n",
    "\n",
    "# SKU_list = pd.concat([SKUs_VM_payg, SKUs_VM_res3y, SKUs_data_disk, SKUs_OS_disk])\n",
    "SKU_list = pd.concat([SKUs_VM_payg, SKUs_VM_res3y, SKUs_data_disk, SKUs_OS_disk])\n",
    "SKU_list_summary = SKU_list.groupby(['pricingModel', 'name', 'SKU']).sum()\n",
    "SKU_list_summary.reset_index(inplace=True)\n",
    "SKU_list_summary.sort_values(['pricingModel','CostPerMonth'], ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "output_file_name = 'sku_quoted.xlsx'\n",
    "if os.path.isfile(os.path.join('.','outputs',output_file_name)):\n",
    "    os.remove(os.path.join('.','outputs',output_file_name))\n",
    "SKU_list_summary.to_excel(os.path.join('.','outputs',output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKUs_VM_payg = output[(output['vmBestPricingModel']=='payg') & (output['Scope']=='In Scope')][['skuVM_payg', 'VMcostPerMonth']]\n",
    "SKUs_VM_payg.columns = ['SKU', 'CostPerMonth']\n",
    "SKUs_data_disk = output[(output['Scope']=='In Scope')][['skuDisk_data_disk', 'disksCostPerMonth']]\n",
    "SKUs_data_disk.columns = ['SKU', 'CostPerMonth']\n",
    "SKUs_OS_disk = output[(output['Scope']=='In Scope')][['skuDisk_OS_disk', 'disksCostPerMonth_OS']]\n",
    "SKUs_OS_disk.columns = ['SKU', 'CostPerMonth']\n",
    "\n",
    "SKU_list = pd.concat([SKUs_VM_payg, SKUs_data_disk, SKUs_OS_disk])\n",
    "\n",
    "SKU_list_summary = SKU_list.groupby('SKU').sum()\n",
    "SKU_list_summary.sort_values('CostPerMonth', ascending=False, inplace=True)\n",
    "\n",
    "output_file_name = 'sku_payg_quoted.xlsx'\n",
    "if os.path.isfile(os.path.join('.','outputs',output_file_name)):\n",
    "    os.remove(os.path.join('.','outputs',output_file_name))\n",
    "SKU_list_summary.to_excel(os.path.join('.','outputs',output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(set(vm_pricing_table_offers['vmName'])).to_excel(os.path.join('.','outputs','vm_names_raw.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_pricing_table_offers_x1 = vm_pricing_table_offers.copy()\n",
    "region = 'europe-west'\n",
    "\n",
    "def extract_features_string(row):\n",
    "    try:\n",
    "        groups = re.search('([^\\d]*)([\\d]+)(-[\\d]+)?([^-v0-9]+)?(v\\d)?(-.*)?', row['vmName']).groups()\n",
    "    except:\n",
    "        groups = (None,None,None,None,None)\n",
    "    return groups\n",
    "\n",
    "\n",
    "vm_pricing_table_offers_x1['groups'] = vm_pricing_table_offers_x1.apply(extract_features_string, axis=1)\n",
    "vm_pricing_table_offers_x1['version'] = vm_pricing_table_offers_x1['groups'].str[4]\n",
    "vm_pricing_table_offers_x1['features'] = vm_pricing_table_offers_x1['groups'].str[3]\n",
    "vm_pricing_table_offers_x1['has_AMD_processor'] = vm_pricing_table_offers_x1['features'].str.contains('a')\n",
    "vm_pricing_table_offers_x1['has_AMD_processor'].fillna(value=False, inplace=True)\n",
    "vm_pricing_table_offers_x1['is_PremiumStorageCapable'] = vm_pricing_table_offers_x1['features'].str.contains('s')\n",
    "vm_pricing_table_offers_x1['is_PremiumStorageCapable'].fillna(value=False, inplace=True)\n",
    "vm_pricing_table_offers_x1['has_ARM_processor'] = vm_pricing_table_offers_x1['features'].str.contains('p')\n",
    "vm_pricing_table_offers_x1['has_ARM_processor'].fillna(value=False, inplace=True)\n",
    "vm_pricing_table_offers_x1['is_isolatedSize'] = vm_pricing_table_offers_x1['features'].str.contains('i')\n",
    "vm_pricing_table_offers_x1['is_isolatedSize'].fillna(value=False, inplace=True)\n",
    "vm_pricing_table_offers_x1['has_blockStoragePerformance'] = vm_pricing_table_offers_x1['features'].str.contains('b')\n",
    "vm_pricing_table_offers_x1['has_blockStoragePerformance'].fillna(value=False, inplace=True)\n",
    "vm_pricing_table_offers_x1['skuVM'] = vm_pricing_table_offers_x1.apply(lambda row: extract_sku(row, region), axis=1)\n",
    "vm_pricing_table_offers_x1['OS'] = vm_pricing_table_offers_x1.apply(lambda row:re.search('^[^-]*-', row['vmName']).group(0), axis=1)\n",
    "vm_pricing_table_offers_x1['priceVmPayg'] = vm_pricing_table_offers_x1.apply(lambda row: extract_price_payg(row, region), axis=1)\n",
    "vm_pricing_table_offers_x1['priceVmRes'] = vm_pricing_table_offers_x1.apply(lambda row: extract_price_3yr(row, region), axis=1)\n",
    "vm_pricing_table_offers_x1['priceVmPayg_perCore'] = vm_pricing_table_offers_x1['priceVmPayg'] / vm_pricing_table_offers_x1['cores']\n",
    "vm_pricing_table_offers_x1['priceVmPayg_perRamGb'] = vm_pricing_table_offers_x1['priceVmPayg'] / vm_pricing_table_offers_x1['ram']\n",
    "#vm_pricing_table_offers_x1['s'] = vm_pricing_table_offers_x1.apply(lambda row:(re.search('[0-9]+s', row['vmName']) is not None), axis=1)\n",
    "#vm_pricing_table_offers_x1['gpu'].replace(to_replace='^$', value='not', inplace=True, regex=True)\n",
    "vm_pricing_table_offers_x1['gpu'].fillna(value=\"none\", inplace=True)\n",
    "vm_pricing_table_offers_x1['diskSize'].fillna(value=0, inplace=True)\n",
    "vm_pricing_table_offers_x1.drop(['prices', 'partNumbers'], axis=1, inplace=True)\n",
    "vm_pricing_table_offers_x1 = vm_pricing_table_offers_x1[vm_pricing_table_offers_x1['offerType']=='compute']\n",
    "vm_pricing_table_offers_x1 = vm_pricing_table_offers_x1.astype({'cores':'float', 'ram':'float', 'priceVmPayg_perCore':'float', 'priceVmPayg_perRamGb':'float'})\n",
    "\n",
    "disk_pricing_table_offers_x1 = disk_pricing_table_offers.copy()\n",
    "disk_pricing_table_offers_x1['priceDisk'] = disk_pricing_table_offers_x1.apply(lambda row: extract_price_disk(row, region), axis=1)\n",
    "disk_pricing_table_offers_x1 = disk_pricing_table_offers_x1[disk_pricing_table_offers_x1['size'].notnull()]\n",
    "disk_pricing_table_offers_x1['diskType'] = disk_pricing_table_offers_x1.apply(lambda row:re.search('^[^-]*-', row['diskName']).group(0), axis=1)\n",
    "disk_pricing_table_offers_x1['redundancy'] = disk_pricing_table_offers_x1.apply(lambda row:re.search('(-zrs|-lrs|$)', row['diskName']).group(0), axis=1)\n",
    "disk_pricing_table_offers_x1['redundancy'].replace(to_replace='^$', value='-lrs', inplace=True, regex=True)\n",
    "disk_pricing_table_offers_x1['diskTypeRedundancy'] = disk_pricing_table_offers_x1['diskType'].str.cat(others=disk_pricing_table_offers_x1['redundancy'])\n",
    "disk_pricing_table_offers_x1['skuDisk'] = disk_pricing_table_offers_x1.apply(lambda row: extract_sku(row, region), axis=1)\n",
    "disk_pricing_table_offers_x1 = disk_pricing_table_offers_x1[disk_pricing_table_offers_x1['skuDisk'].notnull()]\n",
    "disk_pricing_table_offers_x1.drop(['prices', 'partNumbers'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_pricing_table_offers_x1.to_excel(os.path.join('.','outputs','VmPricingTable.xlsx'))\n",
    "disk_pricing_table_offers_x1.to_excel(os.path.join('.','outputs','DiskPricingTable.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = list(pd.unique( vm_pricing_table_offers_x1['features'].values.ravel() ))\n",
    "list_of_features = [i for i in list_of_features if i]\n",
    "list_of_features = \"\".join(list_of_features)\n",
    "list_of_features = set(list_of_features)\n",
    "print(list_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(vm_pricing_table_offers_x1['OS'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=vm_pricing_table_offers_x1\n",
    "        [vm_pricing_table_offers_x1['series'].isin(['Fsv2', 'Bs'])]\n",
    "        [vm_pricing_table_offers_x1['OS'] == 'linux-'],\n",
    "    x='cores',\n",
    "    y='priceVmPayg',\n",
    "    hue='series',\n",
    "    style='series',\n",
    "    size='ram'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_pricing_table_offers_x1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesOrdered = list(vm_pricing_table_offers_x1.groupby('series').aggregate('median').sort_values(by='priceVmPayg_perCore').index)\n",
    "sns.catplot(\n",
    "    data=vm_pricing_table_offers_x1,\n",
    "    x='priceVmPayg_perCore',\n",
    "    y='series',\n",
    "    kind='box',\n",
    "    order=seriesOrdered,\n",
    "    height=16,\n",
    "    aspect=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesOrdered = list(vm_pricing_table_offers_x1.groupby('series').aggregate('median').sort_values(by='priceVmPayg_perRamGb').index)\n",
    "sns.catplot(\n",
    "    data=vm_pricing_table_offers_x1,\n",
    "    x='priceVmPayg_perRamGb',\n",
    "    y='series',\n",
    "    kind='box',\n",
    "    order=seriesOrdered,\n",
    "    height=16,\n",
    "    aspect=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(vm_pricing_table_offers_x1['series'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data=vm_pricing_table_offers_x1[\n",
    "        vm_pricing_table_offers_x1['series'].isin(['Fsv2', 'Dsv5'])\n",
    "    ],\n",
    "    x='cores',\n",
    "    y='priceVmPayg',\n",
    "    hue='series'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
